# -*- coding: utf-8 -*-
"""Proyek Pertama ML Terapan

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XmqGNWRCZ7a1080PYMq7FUAjougL6H_e
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

#Retrieve the data from google drive
zip_path = '/content/drive/MyDrive/archive.zip'

#extract the zip file
try:
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall('/content/data')
    print("Extraction successful.")
except Exception as e:
    print(f"Error: {e}")

import pandas as pd
#Create the dataframe
df = pd.read_csv('/content/data/weather_classification_data.csv')
df.head()

"""#Data Understanding & Data Preparation"""

df.info()

#Check the data shape
df.shape

#Identify Missing Value
df.isna().sum()

#Identify duplicate value
df.duplicated().sum()

import seaborn as sns
sns.boxplot(x=df['Temperature'])

sns.boxplot(x=df['Humidity'])

sns.boxplot(x=df['Wind Speed'])

sns.boxplot(x=df['UV Index'])

sns.boxplot(x=df['Visibility (km)'])

## Function To return index of outlier data

def outlier_idx_finder(df,col):
    q1 = df[col].quantile(0.25)
    q3 = df[col].quantile(0.75)

    iqr = q3 - q1

    upper = q3 + 1.5 * iqr
    lower = q1 - 1.5 * iqr

    ls = df.index[(df[col] < lower) | (df[col] > upper)]
    return ls

outlier_idx = []
num_cols = list(df.select_dtypes(include = ['int', 'float']).columns)

for i in num_cols:

    outlier_idx.extend(outlier_idx_finder(df,i))

outlier_list = set(outlier_idx)

len(outlier_idx)/len(df) * 100

"""The number of outlier data is 13.7% percent of data. It will affect the integrity of the data if I delete it. Therefore, I perform a normalization"""

df.info()

from sklearn.preprocessing import StandardScaler

# Assuming 'df' is your DataFrame with outliers handled
# Select numeric columns for normalization
numeric_cols = df.select_dtypes(include=['int', 'float']).columns

# Apply StandardScaler to normalize numeric columns
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

df.head()

"""Since computer only can recognize numerical value as input. Therefore, I need to encode the columns with object data type"""

categorical_cols = df.select_dtypes(include=['object']).columns

categorical_cols

from sklearn.preprocessing import LabelEncoder
from sklearn.compose import ColumnTransformer
Label_encoder = LabelEncoder()

for feature in categorical_cols:
    df[feature] = Label_encoder.fit_transform(df[feature])

df.head()

mapping = dict(zip(Label_encoder.classes_, Label_encoder.transform(Label_encoder.classes_)))
print(f'Mapping for {feature}: {mapping}')

df['Weather Type'].value_counts()

#Separate the independent and dependent variable
X = df.drop('Weather Type', axis=1)
Y = df['Weather Type']

#Splitting the dataset into train and test sets
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

"""#Modelling and Evaluation"""

from sklearn.neighbors import KNeighborsClassifier
KNN = KNeighborsClassifier()
KNN.fit(X_train, Y_train)

#Evaluate
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
y_pred = KNN.predict(X_test)
accuracy_knn = accuracy_score(Y_test, y_pred)
print(f"The model accuracy is = {accuracy_knn:}")
print(classification_report(Y_test, y_pred))

from sklearn.svm import SVC
SVM = SVC()
SVM.fit(X_train, Y_train)

#EVALUATE
y_pred = SVM.predict(X_test)
accuracy_svm = accuracy_score(Y_test, y_pred)
print(f"The model accuracy is = {accuracy_svm:}")
print(classification_report(Y_test, y_pred))

